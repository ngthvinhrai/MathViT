{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!git clone https://github.com/ngthvinhrai/MathViT.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgTmdCEhi3uN","executionInfo":{"status":"ok","timestamp":1762290590446,"user_tz":-420,"elapsed":2778,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}},"outputId":"e420c6e2-43e5-4761-bda3-7bba03da6014"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MathViT'...\n","remote: Enumerating objects: 35, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 35 (delta 14), reused 34 (delta 13), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (35/35), 4.47 MiB | 7.72 MiB/s, done.\n","Resolving deltas: 100% (14/14), done.\n"]}]},{"cell_type":"markdown","source":["##PARTICULAR"],"metadata":{"id":"_IujsDRyjVLr"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"vcyNmzitfcMR","executionInfo":{"status":"ok","timestamp":1762290632987,"user_tz":-420,"elapsed":41238,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"outputs":[],"source":["import json\n","import torch\n","import gc\n","from torch.utils.data import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSeq2SeqLM,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from torch.optim import AdamW\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si82kIfofo1T","executionInfo":{"status":"ok","timestamp":1762290661588,"user_tz":-420,"elapsed":26973,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}},"outputId":"314f3cab-fd91-46fa-86e2-7ea39086185f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["MODEL_NAME = \"VietAI/vit5-base\"\n","MAX_LENGTH = 512\n","BASE_DATA_PATH = '/content/MathViT/data/vie_base_knowledge.jsonl'\n","PROBLEM_DATA_PATH = '/content/MathViT/data/vie_train.jsonl'\n","THEORY_MODEL_PATH = '/content/drive/MyDrive/RAI/Project/MathViT/model/theory-model'\n","SOLVER_MODEL_PATH = \"/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model\""],"metadata":{"id":"sB9A729ifq1n","executionInfo":{"status":"ok","timestamp":1762290661604,"user_tz":-420,"elapsed":38,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"8MaR6-YWng_5","executionInfo":{"status":"ok","timestamp":1762290661607,"user_tz":-420,"elapsed":22,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class IdentityMappingMathDataset(Dataset):\n","    def __init__(self, data_path, tokenizer, max_length=MAX_LENGTH):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.data = self._prepare_data(data_path)\n","\n","    def _prepare_data(self, data_path):\n","        processed_data = []\n","        with open(data_path, 'r', encoding='utf-8') as f:\n","          for line in f:\n","            item = json.loads(line)\n","            text = item.get('input', '') + \" \" + item.get('output', '')\n","\n","            tokenized = self.tokenizer(\n","                text,\n","                padding='max_length',\n","                truncation=True,\n","                max_length=self.max_length,\n","                return_tensors='pt'\n","            )\n","\n","            labels = tokenized['input_ids'].clone()\n","            input_ids = tokenized['input_ids'].clone()\n","\n","            processed_data.append({\n","                'input_ids': input_ids.squeeze(),\n","                'attention_mask': tokenized['attention_mask'].squeeze(),\n","                'labels': labels.squeeze()\n","            })\n","\n","        return processed_data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]"],"metadata":{"id":"iIvz01YXkSc3","executionInfo":{"status":"ok","timestamp":1762290661611,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class MathDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length=MAX_LENGTH):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        input_text = item['input']\n","        target_text = item['output']\n","\n","        input_encodings = self.tokenizer(input_text, truncation=True, padding='max_length', max_length=self.max_length)\n","        with self.tokenizer.as_target_tokenizer():\n","          target_encodings = self.tokenizer(target_text, truncation=True, padding='max_length', max_length=self.max_length)\n","\n","        return {\n","            'input_ids': torch.tensor(input_encodings['input_ids'], dtype=torch.long),\n","            'attention_mask': torch.tensor(input_encodings['attention_mask'], dtype=torch.long),\n","            'labels': torch.tensor(target_encodings['input_ids'], dtype=torch.long)\n","        }"],"metadata":{"id":"3V4F97aZk0yF","executionInfo":{"status":"ok","timestamp":1762290663694,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def create_differential_optimizer(model, encoder_lr=5e-7, decoder_lr=1e-5):\n","    encoder_params = [p for n, p in model.named_parameters() if 'encoder' in n]\n","    decoder_params = [p for n, p in model.named_parameters() if 'decoder' in n]\n","\n","    optimizer_grouped_parameters = [\n","        {'params': encoder_params, 'lr': encoder_lr},\n","        {'params': decoder_params, 'lr': decoder_lr},\n","    ]\n","\n","    return (AdamW(optimizer_grouped_parameters), None)"],"metadata":{"id":"SPRfdQLSmq85","executionInfo":{"status":"ok","timestamp":1762290664471,"user_tz":-420,"elapsed":14,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"],"metadata":{"id":"3ZP99KBVm1n9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"RJzgyx24njic","executionInfo":{"status":"ok","timestamp":1762284165825,"user_tz":-420,"elapsed":269,"user":{"displayName":"A8. 43. Nguyễn Thành vinh","userId":"14305946220250556975"}},"outputId":"ada546de-2e06-4ef2-8df6-636fe38d2437"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["theory_train_dataset = IdentityMappingMathDataset(BASE_DATA_PATH, tokenizer)"],"metadata":{"id":"YSW18w5Om3r6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["theory_training_args = Seq2SeqTrainingArguments(\n","    output_dir=THEORY_MODEL_PATH,\n","    per_device_train_batch_size=4,\n","    num_train_epochs=8,\n","    learning_rate=1e-5,\n","    save_strategy=\"no\",\n","    logging_dir='./logs/theory',\n","    logging_steps=10\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n","\n","theory_trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=theory_training_args,\n","    train_dataset=theory_train_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer\n",")\n","\n","theory_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"id":"M_GJnm3XnA_s","executionInfo":{"status":"ok","timestamp":1762284319428,"user_tz":-420,"elapsed":100829,"user":{"displayName":"A8. 43. Nguyễn Thành vinh","userId":"14305946220250556975"}},"outputId":"58efce6e-8bb5-4ac4-c0b7-0668acd13fd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-191518760.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  theory_trainer = Seq2SeqTrainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [96/96 01:39, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>23.854300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>13.646400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>6.561500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.539500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.342400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.913600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.733800</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.569900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.546000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=96, training_loss=5.312626736859481, metrics={'train_runtime': 100.3345, 'train_samples_per_second': 3.588, 'train_steps_per_second': 0.957, 'total_flos': 219224840601600.0, 'train_loss': 5.312626736859481, 'epoch': 8.0})"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["model.save_pretrained(THEORY_MODEL_PATH)\n","tokenizer.save_pretrained(THEORY_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0og4cXwnI6E","executionInfo":{"status":"ok","timestamp":1762284333559,"user_tz":-420,"elapsed":6222,"user":{"displayName":"A8. 43. Nguyễn Thành vinh","userId":"14305946220250556975"}},"outputId":"3b437b85-d308-4d08-fae0-ca59ce845988"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Project/MathViT/model/theory-model/tokenizer_config.json',\n"," '/content/drive/MyDrive/Project/MathViT/model/theory-model/special_tokens_map.json',\n"," '/content/drive/MyDrive/Project/MathViT/model/theory-model/spiece.model',\n"," '/content/drive/MyDrive/Project/MathViT/model/theory-model/added_tokens.json',\n"," '/content/drive/MyDrive/Project/MathViT/model/theory-model/tokenizer.json')"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["del theory_trainer\n","del model\n","del tokenizer\n","# Xóa các đối tượng lớn khác\n","# (model và tokenizer sẽ được gán lại ở Giai đoạn 2)\n","gc.collect()\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()"],"metadata":{"id":"PgMNLS7GnRMs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["solver_tokenizer = AutoTokenizer.from_pretrained(SOLVER_MODEL_PATH)\n","solver_model = AutoModelForSeq2SeqLM.from_pretrained(SOLVER_MODEL_PATH)"],"metadata":{"id":"k-tkOUcAnSG1","executionInfo":{"status":"ok","timestamp":1762290698213,"user_tz":-420,"elapsed":27870,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["problem_dataset = []\n","\n","with open(PROBLEM_DATA_PATH, 'r', encoding='utf-8') as f:\n","  for line in f:\n","    problem_dataset.append(json.loads(line))\n","\n","# train_data, val_data = train_test_split(problem_dataset, test_size=0.15, random_state=42)"],"metadata":{"id":"0_ykQTJDAvdT","executionInfo":{"status":"ok","timestamp":1762290710050,"user_tz":-420,"elapsed":79,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["problem_train_dataset = MathDataset(problem_dataset, solver_tokenizer)\n","# problem_val_dataset = MathDataset(val_data, tokenizer)"],"metadata":{"id":"kGkCRM_NnUcP","executionInfo":{"status":"ok","timestamp":1762290710788,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["solver_model.to(device)"],"metadata":{"collapsed":true,"id":"MT61QIUxgWYv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["problem_training_args = Seq2SeqTrainingArguments(\n","    output_dir=SOLVER_MODEL_PATH,\n","    per_device_train_batch_size=4,\n","    num_train_epochs=4,\n","    save_strategy=\"no\",\n","    logging_dir='./logs/solver',\n","    logging_steps=100,\n","    learning_rate=5e-7\n",")\n","\n","problem_trainer = Seq2SeqTrainer(\n","    model=solver_model,\n","    args=problem_training_args,\n","    train_dataset=problem_train_dataset,\n","    tokenizer=solver_tokenizer,\n","    optimizers=create_differential_optimizer(solver_model)\n",")\n","\n","problem_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":770},"id":"OoNZEoGFnvJc","executionInfo":{"status":"ok","timestamp":1762295172793,"user_tz":-420,"elapsed":2132124,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}},"outputId":"ddda7915-fada-4fd8-cb15-580f227a8707"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2979650097.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  problem_trainer = Seq2SeqTrainer(\n","/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1869' max='1869' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1869/1869 35:30, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.247000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.250900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.245800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.245400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.254300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.247000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.251400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.243500</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.255800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.260900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.245200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.250500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.250300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.255200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.274400</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.267000</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.274900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.279700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1869, training_loss=0.25629319629291597, metrics={'train_runtime': 2131.2828, 'train_samples_per_second': 3.506, 'train_steps_per_second': 0.877, 'total_flos': 4550742316154880.0, 'train_loss': 0.25629319629291597, 'epoch': 1.0})"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["solver_model.save_pretrained(SOLVER_MODEL_PATH)\n","solver_tokenizer.save_pretrained(SOLVER_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cw6KFtMn-A_","executionInfo":{"status":"ok","timestamp":1762295861195,"user_tz":-420,"elapsed":9455,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}},"outputId":"c8a00d16-e57d-4216-ca89-e576c5fc3f3e"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model/tokenizer_config.json',\n"," '/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model/special_tokens_map.json',\n"," '/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model/spiece.model',\n"," '/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model/added_tokens.json',\n"," '/content/drive/MyDrive/RAI/Project/MathViT/model/solver-model/tokenizer.json')"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["del problem_trainer\n","gc.collect()\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()"],"metadata":{"id":"H_TmjH9Aunv0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##TEST"],"metadata":{"id":"6DHvnAsoi0qJ"}},{"cell_type":"code","source":["def solve_math_problem(problem_text):\n","    input_ids = solver_tokenizer(\n","        problem_text,\n","        return_tensors=\"pt\",\n","        max_length=512,\n","        truncation=True,\n","        padding=True\n","    ).input_ids.to(device)\n","\n","    with torch.no_grad():\n","      outputs = solver_model.generate(\n","          input_ids,\n","          max_length=512,\n","          num_beams=4,\n","          early_stopping=True,\n","      )\n","\n","    # return outputs\n","    return solver_tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"bazKng2WgcAm","executionInfo":{"status":"ok","timestamp":1762292910350,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["input = [\n","    \"Terry ăn 2 hộp sữa chua mỗi ngày. Hiện tại, chúng đang được bán với giá 4 hộp, mỗi hộp 5 đô la. Vậy anh ấy đã chi bao nhiêu tiền cho sữa chua trong 30 ngày?\",\n","    \"Một đội bóng đá đã chơi 22 trận. Họ thắng nhiều hơn thua 8 trận. Vậy họ đã thắng bao nhiêu trận?\",\n","    \"Một bụi mâm xôi có 6 cụm, mỗi cụm 20 quả và 67 quả riêng lẻ rải rác khắp bụi. Hỏi tổng cộng có bao nhiêu quả mâm xôi?\"\n","]"],"metadata":{"id":"xAT_AbnVggDX","executionInfo":{"status":"ok","timestamp":1762296255840,"user_tz":-420,"elapsed":44,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["solve_math_problem(input[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ewDF6enggd4R","executionInfo":{"status":"ok","timestamp":1762296260728,"user_tz":-420,"elapsed":1527,"user":{"displayName":"Nguyễn Thành Vinh","userId":"05108319913492833601"}},"outputId":"1d117b47-4c9a-4257-e592-8d6e94e3e235"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Mỗi cụm có 6 x 20   6 x 20  120>> 120 quả mâm xôi. Tổng cộng, bụi mâm xôi có 120 + 67   120 + 67  120>> 120 quả mâm xôi.  120'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]}]}